{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56e257d6-ea5a-4fda-892a-7b4a0fcfb518",
   "metadata": {},
   "source": [
    "# Handwriting decoder evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e59640-652c-46ee-bc15-2bd4abbe9105",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from pytorch_lightning import Trainer\n",
    "from hydra import initialize, compose\n",
    "from hydra.utils import instantiate\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "from generic_neuromotor_interface.data import make_handwriting_dataset\n",
    "from generic_neuromotor_interface.handwriting_utils import CharacterErrorRates\n",
    "\n",
    "TASK_NAME = \"handwriting\"\n",
    "EMG_DATA_DIR = \"~/emg_data\"  # path to EMG data\n",
    "MODELS_DIR = \"~/emg_models\"  # path to model files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7888a27-a4e0-4d80-9ae5-0bfae2991055",
   "metadata": {},
   "source": [
    "## Download Data Subset and Model Files\n",
    "\n",
    "Before running this notebook, make sure you have downloaded the data (small subset) and model checkpoint.\n",
    "\n",
    "You can do so with the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67741eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equivalent to README instructions.\n",
    "\n",
    "from generic_neuromotor_interface.scripts.download_data import download_data\n",
    "from generic_neuromotor_interface.scripts.download_models import download_models\n",
    "\n",
    "download_data(TASK_NAME, \"small_subset\", EMG_DATA_DIR)\n",
    "download_models(TASK_NAME, MODELS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c3bfae-0335-4ef1-b182-e28a0d4cac24",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.expanduser(EMG_DATA_DIR)):\n",
    "    raise FileNotFoundError(f\"The EMG data path does not exist: {EMG_DATA_DIR}\")\n",
    "\n",
    "if not os.path.exists(os.path.expanduser(MODELS_DIR)):\n",
    "    raise FileNotFoundError(f\"The models path does not exist: {MODELS_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf3f201-0006-4ec9-a5bf-6a8583a1b450",
   "metadata": {},
   "source": [
    "## Load model config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5220619a-3102-49bc-8c8b-e608c8bc9ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Load model config\"\"\"\n",
    "\n",
    "config_path = os.path.join(os.path.expanduser(MODELS_DIR), TASK_NAME, \"model_config.yaml\")\n",
    "config = OmegaConf.load(config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40cf1f5-d667-44a4-b7bd-3f0b1af56909",
   "metadata": {},
   "source": [
    "## Load model checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19766bb3-a366-4a9b-a118-f9923d343ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Load model checkpoint\"\"\"\n",
    "\n",
    "model_ckpt_path = os.path.join(\n",
    "    os.path.expanduser(MODELS_DIR),\n",
    "    TASK_NAME,\n",
    "    \"model_checkpoint.ckpt\"\n",
    ")\n",
    "model = instantiate(config.lightning_module)\n",
    "model = model.load_from_checkpoint(\n",
    "    model_ckpt_path,\n",
    "    map_location=torch.device(\"cpu\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b3b308-0713-419e-9af3-37fa36274909",
   "metadata": {},
   "source": [
    "## Instantiate data module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b92765-b05a-49c8-9ac6-ea4a603eaf74",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Assemble the data module\"\"\"\n",
    "\n",
    "# Update DataModule config with data path\n",
    "config[\"data_module\"][\"data_location\"] = os.path.expanduser(EMG_DATA_DIR)\n",
    "if \"from_csv\" in config[\"data_module\"][\"data_split\"][\"_target_\"]:\n",
    "    config[\"data_module\"][\"data_split\"][\"csv_filename\"] = os.path.join(\n",
    "        os.path.expanduser(EMG_DATA_DIR),\n",
    "        f\"{TASK_NAME}_corpus.csv\"\n",
    "    )\n",
    "\n",
    "datamodule = instantiate(config[\"data_module\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582efd05-02e4-4cdb-9c9d-8ecbd1d1d9f2",
   "metadata": {},
   "source": [
    "## Run inference on one prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef1e0b6-31e5-4106-af02-0e7446f8993d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Grab one test prompt\"\"\"\n",
    "\n",
    "test_dataset = make_handwriting_dataset(\n",
    "    dataset_names=[\"handwriting_user_001_dataset_000\"],\n",
    "    data_location=datamodule.data_location,\n",
    "    transform=datamodule.transform,\n",
    "    padding=datamodule.padding,\n",
    "    emg_augmentation=None,\n",
    "    concatenate_prompts=False,\n",
    "    min_duration_s=0.0,\n",
    ")\n",
    "\n",
    "sample = test_dataset[55]  # an arbitrary prompt from this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a087ba3b-d0b8-433f-9f97-2260d5b201e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Run inference\"\"\"\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# unpack sample\n",
    "emg = sample[\"emg\"]\n",
    "labels = sample[\"prompts\"]\n",
    "\n",
    "# compute model outputs\n",
    "with torch.no_grad():\n",
    "    emissions, _slice = model(emg.T.unsqueeze(0))\n",
    "\n",
    "    # compute greedy decode outputs\n",
    "    predictions = model.decoder.decode_batch(\n",
    "        emissions=emissions.movedim(0, 1).numpy(),\n",
    "        emission_lengths=model.network.compute_time_downsampling(\n",
    "            emg_lengths=torch.as_tensor([len(emg)]), slc=_slice\n",
    "        )\n",
    "    )\n",
    "\n",
    "predictions = torch.as_tensor(predictions[0])\n",
    "\n",
    "# convert predictions and labels to characters\n",
    "predictions = model.decoder._charset.labels_to_str(predictions)\n",
    "labels = model.decoder._charset.labels_to_str(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2abd035-9682-4e8f-b209-7178aa7918eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Evaluate CER on this prompt\"\"\"\n",
    "\n",
    "metric = CharacterErrorRates()\n",
    "metric.update(\n",
    "    prediction=predictions,\n",
    "    target=labels,\n",
    ")\n",
    "aggregate_metrics = metric.compute()\n",
    "\n",
    "print(\"CER of above prompt decode:\", aggregate_metrics[\"CER\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5059309d-d784-4fc2-bfb3-843a39e67986",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Print predictions and target\"\"\"\n",
    "\n",
    "print(\n",
    "    f\"Prediction: \\t {predictions} \\n\"\n",
    "    f\"Target: \\t {labels}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1673e06-9133-486e-9766-64e55f0be4d3",
   "metadata": {},
   "source": [
    "## Evaluate full test set\n",
    "\n",
    "Note that this requires you to have downloaded the full dataset (uncomment the below lines)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7114195",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Uncomment to download the full dataset\n",
    "\n",
    "# from generic_neuromotor_interface.scripts.download_data import download_data\n",
    "# download_data(TASK_NAME, \"full_data\", EMG_DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0d7e8a-2006-46c8-925c-7253007d5060",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(accelerator=\"cpu\")\n",
    "test_results = trainer.test(model=model, datamodule=datamodule)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuromotor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
